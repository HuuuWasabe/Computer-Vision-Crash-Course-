{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO. 2**</u> | <u>**Basic I/O Scripting, Part 1**</u>\n",
        "**Name** | LastName, FirstName\n",
        "**Section** | CPE31Sx\n",
        "**Date Performed**: |\n",
        "**Date Submitted**: |\n",
        "**Instructor**: | Dr. Jonathan V. Taylar / Engr. Verlyn V. Nojor / Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to introduce students to the OpenCV's I/O functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Read and write an image file\n",
        "* Convert between image and raw bytes\n",
        "* Access image data with numpy.array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayqjBYJaUE6j"
      },
      "source": [
        "Most CV applications need to get images as input. Most also produce images as output. An interactive CV application might require a camera as an input source\n",
        "and a window as an output destination. However, other possible sources and destinations include image files, video files, and raw bytes.\n",
        "\n",
        "For example, raw bytes might be transmitted via a network connection, or they might be generated by an\n",
        "algorithm if we incorporate procedural graphics into our application. Let's look at each of these possibilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwn_Q627UpXq"
      },
      "source": [
        "### 4.1 Reading and Writing Image Files\n",
        "\n",
        "OpenCV provides the ```imread()``` and ```imwrite()``` functions that support various file formats for still images. The supported formats vary by system but should always include the BMP format. Typically, PNG, JPEG, and TIFF should be among the supported formats too. Let's explore the anatomy of the representation of an image in Python and NumPy. No matter the format, each pixel has a value, but the difference is in how the pixel is represented.\n",
        "\n",
        "For example, we can create a black square image from scratch by simply creating a 2D NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VROloZkwVelo"
      },
      "outputs": [],
      "source": [
        "# Uncomment if you encounter an error importing numpy\n",
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "img = np.zeros((3,3), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJpyJ2jVCLS"
      },
      "source": [
        "If we print this image to a console, we obtain the following result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFJLDEYVGK5",
        "outputId": "1447ff00-e728-4b91-d92b-bc6f06a07226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0olzWTwZX0pk"
      },
      "source": [
        "Each pixel is represented by a single 8-bit integer, which means that the values for each pixel are in the 0-255 range.\n",
        "\n",
        "Let's now convert this image into Blue-green-red (BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QrNAP45KX5mU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb674mZvYLAE"
      },
      "source": [
        "**What changes can you observe when you print ```img```?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "K1ikufCFYTJU",
        "outputId": "56752cca-8ce2-4b05-9cdd-8b8caa79cbf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' The img array added 2 more arrays, this is because we added colors to the array '"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code Here\n",
        "print(img)\n",
        "\n",
        "\"\"\" The img array added 2 more arrays, this is because we added colors to the array \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2o6MdnwYzkD"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "You can check the structure of an image by inspecting the shape property, which returns rows, columns, and the number of channels (if there is more than one).\n",
        "\n",
        "Consider this example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ta1kLA2Y2ar",
        "outputId": "bd7c2730-75d7-47bd-b2bf-9e75fa61d313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = np.zeros((3,3), dtype=np.uint8)\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OkQv4O7ZAca"
      },
      "source": [
        "If you then converted the image to BGR, the shape would be (3,3,3), which indicates the presence of three channels per pixel.\n",
        "\n",
        "Images can be loaded from one file format and saved to another. For example, let's convert an image from PNG to JPEG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjYqdXpKY-MS",
        "outputId": "1a76dfbf-22f1-4898-dfae-771e90d0395b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = cv2.imread('data/Yhwach_Anime.png')\n",
        "cv2.imwrite('data/Yhwach_Anime.jpg', image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(612, 703, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Checking image shape\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEPZoIwahdA"
      },
      "source": [
        "By default, imread() returns an image in the BGR color format even if the file uses a grayscale format. BGR represents the same color space as red-green-blue (RGB), but the byte order is reversed.\n",
        "\n",
        "Optionally, we may specify the mode of imread() to be one of the following enumerators:\n",
        "* ```IMREAD_ANYCOLOR = 4```\n",
        "* ```IMREAD_ANYDEPTH = 2```\n",
        "* ```IMREAD_COLOR = 1```\n",
        "* ```IMREAD_GRAYSCALE = 0```\n",
        "* ```IMREAD_LOAD_GDAL = 8```\n",
        "* ```IMREAD_UNCHANGED = -1```\n",
        "\n",
        "For example, let's load a PNG file as a grayscale image (losing any color information in the process), and then, save it as a grayscale PNG image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-msCfBb8YzLz",
        "outputId": "9121797f-3ac4-4ceb-cbc7-41f30809a4ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grayImage = cv2.imread('data/Yhwach_Anime.png', cv2.IMREAD_GRAYSCALE)\n",
        "cv2.imwrite('data/GrayYhwach.png', grayImage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKO1-lstbUV3"
      },
      "source": [
        "*Note: Regardless of the mode, imread() discards any alpha channel (transparency). The imwrite() function requires an image to be in the BGR or grayscale format with a certain number of bits per channel that the output format can support. For example,\n",
        "bmp requires 8 bits per channel, while PNG allows either 8 or 16 bits per channel.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ru8da__bb8u"
      },
      "source": [
        "### 4.2 Converting between an image and raw bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYdQUeDcQCl"
      },
      "source": [
        "Conceptually, a byte is an integer ranging from 0 to 255. In all real-time graphic applications today, a pixel is typically represented by one byte per channel, though other representations are also possible.\n",
        "\n",
        "An OpenCV image is a 2D or 3D array of the .array type. An 8-bit grayscale image is a 2D array containing byte values. A 24-bit BGR image is a 3D array, which also contains byte values. We may access these values by using an expression, such as ```image[0, 0]``` or ```image[0, 0, 0]```. The first index is the pixel's y coordinate or row, 0 being the top. The second index is the pixel's x coordinate or column, 0 being the leftmost. The third index (if applicable) represents a color channel.\n",
        "\n",
        "For example, in an 8-bit grayscale image with a white pixel in the upper-left corner,\n",
        "```image[0, 0]``` is 255. For a 24-bit BGR image with a blue pixel in the upper-left\n",
        "corner, ```image[0, 0]``` is ```[255, 0, 0]```.\n",
        "\n",
        "Provided that an image has 8 bits per channel, we can cast it to a standard Python bytearray, which is one-dimensional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KX7aafETa6He"
      },
      "outputs": [],
      "source": [
        "byteArray = bytearray(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95-_dhCGc5jE"
      },
      "source": [
        "Conversely, provided that ```bytearray``` contains bytes in an appropriate order, we can cast and then reshape it to get a ```numpy.array``` type that is an image. As a more complete example, let's convert bytearray, which contains random bytes to a grayscale image and a BGR image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWd7LzuAbY_3",
        "outputId": "bbc4a363-043a-4a7b-b04d-53478b552a77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Make an array of 120,000 random bytes\n",
        "randomByteArray = bytearray(os.urandom(120000))\n",
        "flatNumpyArray = np.array(randomByteArray)\n",
        "\n",
        "# Convert the array to make a 400x300 grayscale image\n",
        "grayImage = flatNumpyArray.reshape(300,400)\n",
        "cv2.imwrite('data/RandomGray.png', grayImage)\n",
        "\n",
        "# Convert the array to make a 400x100 color image\n",
        "bgrImage = flatNumpyArray.reshape(100,400,3)\n",
        "cv2.imwrite('data/RandomColor.png', bgrImage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCqqLw4Ld0ta"
      },
      "source": [
        "After running this script, we should have a pair of randomly generated images, RandomGray.png and RandomColor.png, in the script's directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzgausTgeAIa"
      },
      "source": [
        "### 4.3 Accessing image data with numpy.array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNq4-j9reDPa"
      },
      "source": [
        "Now that you have a better understanding of how an image is formed, we can start performing basic operations on it. We know that the easiest (and most common) way to load an image in OpenCV is to use the imread function. We also know that this will return an image, which is really an array (either a 2D or 3D one, depending on\n",
        "the parameters you passed to imread()).\n",
        "\n",
        "The y.array structure is well optimized for array operations, and it allows certain kinds of bulk manipulations that are not available in a plain Python list. These kinds of .array type-specific operations come in handy for image manipulations in OpenCV.\n",
        "\n",
        "Let's explore image manipulations from the start and step by step though, with a basic example: say you want to manipulate a pixel at the coordinates, (0, 0), of a BGR image and turn it into a white pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6ZYNjFMPeN6Z"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('data/Yhwach_Anime.png')\n",
        "img[0:25, 0:25] = [0,0,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6u6IgzFeaJp"
      },
      "source": [
        "If you then showed the image with a standard imshow() call, you will see a black square in the top-left corner of the image. Naturally, this isn't very useful, but it shows what can be accomplished. Let's now leverage the ability of numpy.array to operate transformations to an array much faster than a plain Python array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P2jSleVyeZvW",
        "outputId": "056ba843-0597-4038-8acf-1e04b309f3e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A window with the image popped out.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = cv2.imread('data/Yhwach_Anime.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2.imshow('TheAlmighty',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# If running in Colab, uncomment code above and comment the codes below\n",
        "##from google.colab.patches import cv2_imshow\n",
        "##cv2_imshow(img)\n",
        "\n",
        "'''A window with the image popped out.'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p align=\"center\">\n",
        "    <img width=\"800\" height=\"480\" src=\"image_window.png\" alt=\"The Almighty\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PstHP8gFie"
      },
      "source": [
        "Let's say that you want to change the blue value of a particular pixel, for example, the pixel at coordinates, (150, 120). The ```numpy.array``` type provides a very handy method, item(), which takes three parameters: the x (or left) position, y (or top), and the index within the array at (x, y) position (remember that in a BGR image, the data at a certain position is a three-element array containing the B, G, and R values in this order) and returns the value at the index position. Another ```itemset()``` method sets the value of a particular channel of a particular pixel to a specified value (```itemset()``` takes two arguments: a three-element tuple (x, y, and index) and the new value).\n",
        "\n",
        "In this example, we will change the value of blue at (150, 120) from its current value to an arbitrary 127:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Og4u2hgcEG",
        "outputId": "26ae9c9d-ad1a-4d63-aea5-4593feb1122f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('data/Yhwach_Anime.png')\n",
        "print(img.item(150,120,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LzChkYgpE-",
        "outputId": "5e7c2d11-f64f-456c-d106-3dc863cb4396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127\n"
          ]
        }
      ],
      "source": [
        "img.itemset((150,120,0), 127)\n",
        "print(img.item(150,120,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0RPq9yFg4Zd"
      },
      "source": [
        "Remember that we do this with ```numpy.array``` for two reasons: ```numpy.array``` is an extremely optimized library for these kind of operations, and because we obtain more readable code through NumPy's elegant methods rather than the raw index access of the first example.\n",
        "\n",
        "This particular code doesn't do much in itself, but it does open a world of possibilities. It is, however, advisable that you utilize built-in filters and methods to manipulate an entire image; the above approach is only suitable for small regions of interest.\n",
        "\n",
        "Now, let's take a look at a very common operation, namely, manipulating channels. Sometimes, you'll want to zero-out all the values of a particular channel (B, G, or R)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CAK6V88hFcU"
      },
      "source": [
        "This is a fairly impressive piece of code and easy to understand. The relevant line is the last one, which basically instructs the program to take all pixels from all rows and columns and set the resulting value at index one of the three-element array, representing the color of the pixel to 0. If you display this image, you will notice a\n",
        "complete absence of green.\n",
        "\n",
        "There are a number of interesting things we can do by accessing raw pixels with NumPy's array indexing; one of them is defining regions of interests (ROI). Once the region is defined, we can perform a number of operations, namely, binding this region to a variable, and then even defining a second region and assigning it the value of the first one (visually copying a portion of the image over to another\n",
        "position in the image):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X0Q7JyaWg4LM"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('data/Yhwach_Anime.png')\n",
        "my_roi = img[0:100, 0:100]\n",
        "img[300:400, 300:400] = my_roi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1c8KTChmhYwk",
        "outputId": "ee393e8f-2bb3-4388-e5eb-59725ce627bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There is a hole in the center of the image'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the image with the roi indicated as shown in the code above\n",
        "cv2.imshow(\"The Almighty\", img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "'''There is a hole in the center of the image'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p align=\"center\">\n",
        "    <img width=\"800\" height=\"480\" src=\"image_window_roi.png\" alt=\"The Almighty\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8VX9Pk_hc_8"
      },
      "source": [
        "It's important to make sure that the two regions correspond in terms of size. If not, NumPy will (rightly) complain that the two shapes mismatch.\n",
        "\n",
        "Finally, there are a few interesting details we can obtain from numpy.array, such as the image properties using this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4WtlyOmhi6E",
        "outputId": "4f848a8e-6084-4879-af41-bdd3b89ae5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(612, 703, 3)\n",
            "1290708\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "img = cv2.imread('data\\Yhwach_Anime.png')\n",
        "print(img.shape)\n",
        "print(img.size)\n",
        "print(img.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tShjQtohszb"
      },
      "source": [
        "These three properties are in this order:\n",
        "* **Shape**: NumPy returns a tuple containing the width, height, and—if the image is in color—the number of channels. This is useful to debug a type of image; if the image is monochromatic or grayscale, it will not contain a channel's value.\n",
        "* **Size**: This property refers to the size of an image in pixels.\n",
        "* **Datatype**: This property refers to the datatype used for an image (normally a variation of an unsigned integer type and the bits supported by this type, that is, uint8).\n",
        "\n",
        "All in all, it is strongly advisable that you familiarize yourself with NumPy in general and numpy.array in particular when working with OpenCV, as it is the foundation of an image processing done with Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP3-Vu3lh-nL"
      },
      "source": [
        "Perform the following tasks, add code blocks below to demonstrate each.\n",
        "\n",
        "1. Load an RBG .png image of your favorite fictional character (animated is allowed). Make sure that they have a face that can be seen in the image.\n",
        "2. Display the image.\n",
        "3. Change the file type to .jpg then display the image.\n",
        "4. Create a new image file that is a grayscale version of the original image from #1.\n",
        "5. Use all 6 enumerators of the ```cv2.imread()``` function and provide an observation for each.\n",
        "6. Experiment with values to obtain an ROI that captures the full face of your favorite character. Display this new image.\n",
        "7. Save the new image from from #6 as \"character_face.png\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "N-3Tp4EyKvyK",
        "outputId": "069870b2-daff-4385-c4fc-80fa67d58d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Window showed image of character'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Load rgb image and display\n",
        "my_img = cv2.imread('data\\Black_Hanekawa.png')\n",
        "cv2.imshow(\"Cat\", my_img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "'''Window showed image of character'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p align=\"center\">\n",
        "    <img width=\"800\" height=\"480\" src=\"image_window2.png\" alt=\"The Cat\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output is the same but the file format is now different'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Change image format from .png to .jpg\n",
        "jpg_img = cv2.imread('data\\Black_Hanekawa.png')\n",
        "cv2.imwrite('data\\Black_Hanekawa.jpg', jpg_img)\n",
        "\n",
        "cv2.imshow(\"Hanekawa\",cv2.imread('data\\Black_Hanekawa.jpg'))\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "'''The output is the same but the file format is now different'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
